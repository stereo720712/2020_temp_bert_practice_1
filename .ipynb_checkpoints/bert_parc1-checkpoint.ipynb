{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./bert-master')\n",
    "import numpy as np # linear algebra\n",
    "import re, os\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "\n",
    "# BERT\n",
    "import optimization\n",
    "import run_classifier\n",
    "import tokenization\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.0'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 13091912688464239505\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 6576128000\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 9538767572507644665\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 2080 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the file details\n",
    "directory = []\n",
    "file = []\n",
    "title = []\n",
    "text = []\n",
    "label = []\n",
    "datapath = './bbc-fulltext (document classification)/bbc/' \n",
    "for dirname, _ , filenames in os.walk(datapath):\n",
    "    #print('Directory: ', dirname)\n",
    "    #print('Subdir: ', dirname.split('/')[-1])\n",
    "    # remove the Readme.txt file\n",
    "    # will not find file in the second iteration so we skip the error\n",
    "    try:\n",
    "        filenames.remove('README.TXT')\n",
    "    except:\n",
    "        pass\n",
    "    for filename in filenames:\n",
    "        directory.append(dirname)\n",
    "        file.append(filename)\n",
    "        label.append(dirname.split('/')[-1])\n",
    "        fullpathfile = os.path.join(dirname,filename)\n",
    "        with open(fullpathfile, 'r', encoding=\"utf8\", errors='ignore') as infile:\n",
    "            intext = ''\n",
    "            firstline = True\n",
    "            for line in infile:\n",
    "                if firstline:\n",
    "                    title.append(line.replace('\\n',''))\n",
    "                    firstline = False\n",
    "                else:\n",
    "                    intext = intext + ' ' + line.replace('\\n','')\n",
    "            text.append(intext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quarterly profits at US media giant TimeWarn...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The dollar has hit its highest level against...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The owners of embattled Russian oil giant Yu...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>British Airways has blamed high fuel prices ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shares in UK drinks and food firm Allied Dom...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     label\n",
       "0    Quarterly profits at US media giant TimeWarn...  business\n",
       "1    The dollar has hit its highest level against...  business\n",
       "2    The owners of embattled Russian oil giant Yu...  business\n",
       "3    British Airways has blamed high fuel prices ...  business\n",
       "4    Shares in UK drinks and food firm Allied Dom...  business"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_COLUMN = 'text'\n",
    "LABEL_COLUMN = 'label'\n",
    "\n",
    "fulldf = pd.DataFrame(list(zip(directory, file, title, text, label)), \n",
    "               columns =['directory', 'file', 'title', 'text', 'label'])\n",
    "\n",
    "df = fulldf.filter(['text','label'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking number of records of each label\n",
    "df['label'].value_counts().sort_values(ascending=False).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quarterly profits at US media giant TimeWarn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The dollar has hit its highest level against...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The owners of embattled Russian oil giant Yu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>British Airways has blamed high fuel prices ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shares in UK drinks and food firm Allied Dom...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0    Quarterly profits at US media giant TimeWarn...      0\n",
       "1    The dollar has hit its highest level against...      0\n",
       "2    The owners of embattled Russian oil giant Yu...      0\n",
       "3    British Airways has blamed high fuel prices ...      0\n",
       "4    Shares in UK drinks and food firm Allied Dom...      0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode label\n",
    "le = LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['label'])\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Razer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk  \n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# prepossing text\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing. \n",
    "#     text = re.sub(r'\\W+', '', text)\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # remove stopwors from text\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>quarterly profits us media giant timewarner ju...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dollar hit highest level euro almost three mon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>owners embattled russian oil giant yukos ask b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>british airways blamed high fuel prices  drop ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>shares uk drinks food firm allied domecq risen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  quarterly profits us media giant timewarner ju...      0\n",
       "1  dollar hit highest level euro almost three mon...      0\n",
       "2  owners embattled russian oil giant yukos ask b...      0\n",
       "3  british airways blamed high fuel prices  drop ...      0\n",
       "4  shares uk drinks food firm allied domecq risen...      0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['text'].apply(clean_text)\n",
    "df['text'] = df['text'].str.replace('\\d+', '')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Processing text for BERT model\n",
    "def get_split(text1):\n",
    "    l_total = []\n",
    "    l_parcial = []\n",
    "    if len(text1.split())//150 >0:\n",
    "        n = len(text1.split())//150\n",
    "    else: \n",
    "        n = 1\n",
    "    for w in range(n):\n",
    "        if w == 0:\n",
    "            l_parcial = text1.split()[:200]\n",
    "            l_total.append(\" \".join(l_parcial))\n",
    "        else:\n",
    "            l_parcial = text1.split()[w*150:w*150 + 200]\n",
    "            l_total.append(\" \".join(l_parcial))\n",
    "    return l_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>quarterly profits us media giant timewarner ju...</td>\n",
       "      <td>0</td>\n",
       "      <td>[quarterly profits us media giant timewarner j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dollar hit highest level euro almost three mon...</td>\n",
       "      <td>0</td>\n",
       "      <td>[dollar hit highest level euro almost three mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>owners embattled russian oil giant yukos ask b...</td>\n",
       "      <td>0</td>\n",
       "      <td>[owners embattled russian oil giant yukos ask ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>british airways blamed high fuel prices  drop ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[british airways blamed high fuel prices drop ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>shares uk drinks food firm allied domecq risen...</td>\n",
       "      <td>0</td>\n",
       "      <td>[shares uk drinks food firm allied domecq rise...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  quarterly profits us media giant timewarner ju...      0   \n",
       "1  dollar hit highest level euro almost three mon...      0   \n",
       "2  owners embattled russian oil giant yukos ask b...      0   \n",
       "3  british airways blamed high fuel prices  drop ...      0   \n",
       "4  shares uk drinks food firm allied domecq risen...      0   \n",
       "\n",
       "                                          text_split  \n",
       "0  [quarterly profits us media giant timewarner j...  \n",
       "1  [dollar hit highest level euro almost three mo...  \n",
       "2  [owners embattled russian oil giant yukos ask ...  \n",
       "3  [british airways blamed high fuel prices drop ...  \n",
       "4  [shares uk drinks food firm allied domecq rise...  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text_split'] = df['text'].apply(get_split)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Model output directory: bert_news_category *****\n"
     ]
    }
   ],
   "source": [
    "#Setting output directory for BERT\n",
    "OUTPUT_DIR = 'bert_news_category'\n",
    "\n",
    "#@markdown Whether or not to clear/delete the directory and create a new one\n",
    "DO_DELETE = True #@param {type:\"boolean\"}\n",
    "\n",
    "if DO_DELETE:\n",
    "    try:\n",
    "        tf.gfile.DeleteRecursively(OUTPUT_DIR)\n",
    "#         tf.compat.v1.gfile.DeleteRecursively(OUTPUT_DIR)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
    "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>crude oil prices surged back  barrel mark thur...</td>\n",
       "      <td>0</td>\n",
       "      <td>[crude oil prices surged back barrel mark thur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>us rock band rem forced cancel concerts bass p...</td>\n",
       "      <td>1</td>\n",
       "      <td>[us rock band rem forced cancel concerts bass ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  crude oil prices surged back  barrel mark thur...      0   \n",
       "1  us rock band rem forced cancel concerts bass p...      1   \n",
       "\n",
       "                                          text_split  \n",
       "0  [crude oil prices surged back barrel mark thur...  \n",
       "1  [us rock band rem forced cancel concerts bass ...  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SPLIT DATA\n",
    "train, val = train_test_split(df, test_size=0.2, random_state=35)\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get labels\n",
    "label_list = [x for x in np.unique(train.label)]\n",
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>actor keanu reeves best known role matrix movi...</td>\n",
       "      <td>1</td>\n",
       "      <td>[actor keanu reeves best known role matrix mov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>labour party hold  autumn conference mancheste...</td>\n",
       "      <td>2</td>\n",
       "      <td>[labour party hold autumn conference mancheste...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  actor keanu reeves best known role matrix movi...      1   \n",
       "1  labour party hold  autumn conference mancheste...      2   \n",
       "\n",
       "                                          text_split  \n",
       "0  [actor keanu reeves best known role matrix mov...  \n",
       "1  [labour party hold autumn conference mancheste...  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.reset_index(drop=True, inplace=True)\n",
    "val.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2171, 2171, 2171)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_l = []\n",
    "label_l = []\n",
    "index_l =[]\n",
    "for idx,row in train.iterrows():\n",
    "    for l in row['text_split']:\n",
    "        train_l.append(l)\n",
    "        label_l.append(row['label'])\n",
    "        index_l.append(idx)\n",
    "len(train_l), len(label_l), len(index_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(543, 543, 543)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_l = []\n",
    "val_label_l = []\n",
    "val_index_l = []\n",
    "for idx,row in val.iterrows():\n",
    "    for l in row['text_split']:\n",
    "        val_l.append(l)\n",
    "        val_label_l.append(row['label'])\n",
    "        val_index_l.append(idx)\n",
    "len(val_l), len(val_label_l), len(val_index_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>crude oil prices surged back barrel mark thurs...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>us rock band rem forced cancel concerts bass p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chinese police detained three top executives m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>writing microsoft word document dangerous busi...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>snow patrol course action ask cofounder bassis...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  crude oil prices surged back barrel mark thurs...      0\n",
       "1  us rock band rem forced cancel concerts bass p...      1\n",
       "2  chinese police detained three top executives m...      0\n",
       "3  writing microsoft word document dangerous busi...      4\n",
       "4  snow patrol course action ask cofounder bassis...      1"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting train and validation set as dataframe¶\n",
    "train_df = pd.DataFrame({DATA_COLUMN:train_l, LABEL_COLUMN:label_l})\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>actor keanu reeves best known role matrix movi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>labour party hold autumn conference manchester...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>us actor ossie davis found dead age davis marr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>computer firm apple issued lawsuit prevent onl...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>labours leadership put show unity campaign pos...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  actor keanu reeves best known role matrix movi...      1\n",
       "1  labour party hold autumn conference manchester...      2\n",
       "2  us actor ossie davis found dead age davis marr...      1\n",
       "3  computer firm apple issued lawsuit prevent onl...      4\n",
       "4  labours leadership put show unity campaign pos...      2"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = pd.DataFrame({DATA_COLUMN:val_l, LABEL_COLUMN:val_label_l})\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       <run_classifier.InputExample object at 0x00000...\n",
       "1       <run_classifier.InputExample object at 0x00000...\n",
       "2       <run_classifier.InputExample object at 0x00000...\n",
       "3       <run_classifier.InputExample object at 0x00000...\n",
       "4       <run_classifier.InputExample object at 0x00000...\n",
       "                              ...                        \n",
       "1775    <run_classifier.InputExample object at 0x00000...\n",
       "1776    <run_classifier.InputExample object at 0x00000...\n",
       "1777    <run_classifier.InputExample object at 0x00000...\n",
       "1778    <run_classifier.InputExample object at 0x00000...\n",
       "1779    <run_classifier.InputExample object at 0x00000...\n",
       "Length: 1780, dtype: object"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Fine tuning the BERT model\n",
    "The BERT model can be applied for any kind of classification task by fine-tuning it.\n",
    "\n",
    "1. Preparing the input data, i.e create InputExample using the BERT’s constructor.\n",
    "'''\n",
    "# Use the InputExample class from BERT's run_classifier code to create examples from the data\n",
    "train_InputExamples = train.apply(lambda x: run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n",
    "                                                                   text_a = x[DATA_COLUMN], \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "val_InputExamples = val.apply(lambda x: run_classifier.InputExample(guid=None, \n",
    "                                                                   text_a = x[DATA_COLUMN], \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
    "train_InputExamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "BERT_MODEL_HUB2 = os.sep.join([\".\",\"sean_bert_uncased_L-12_H-768_A-12_1\"])\n",
    "#\"D:\\git_r\\bert_parc1\\sean_bert_uncased_L-12_H-768_A-12_1z\"\n",
    "def create_tokenizer_from_hub_module():\n",
    "  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "  with tf.Graph().as_default():\n",
    "    bert_module = hub.Module(BERT_MODEL_HUB)\n",
    "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "    with tf.Session() as sess:\n",
    "#     with tf.compat.v1.Session() as sess:\n",
    "        vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
    "                                            tokenization_info[\"do_lower_case\"]])\n",
    "      \n",
    "    return tokenization.FullTokenizer(\n",
    "      vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "tokenizer = create_tokenizer_from_hub_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['crude', 'oil', 'prices', 'surged', 'back', 'barrel', 'mark', 'thursday', 'energy', 'market', 'watch', '##dog', 'raised', 'forecast', '##s', 'global', 'demand', 'international', 'energy', 'agency', 'ie', '##a', 'warned', 'demand', 'op', '##ec', '##s', 'crude', 'first', 'quarter', 'would', 'outs', '##trip', 'supply', 'ie', '##a', 'raised', 'estimate', 'oil', 'demand', 'growth', 'barrels', 'day', 'million', 'barrels', 'day', 'us', 'light', 'crude', 'rose', 'brent', 'crude', 'london', 'gained', 'paris', '##base', '##d', 'ie', '##a', 'watch', '##dog', 'advises', 'industrial', '##ized', 'nations', 'energy', 'policy', 'said', 'upward', 'revision', 'due', 'stronger', 'demand', 'china', 'asian', 'countries', 'fresh', 'rally', 'crude', 'prices', 'followed', 'gains', 'wednesday', 'triggered', 'large', 'falls', 'us', 'crude', 'supplies', 'following', 'cold', 'spell', 'north', 'america', 'january', 'us', 'department', 'energy', 'reported', 'crude', 'stock', '##pile', '##s', 'fallen', 'm', 'barrels', 'm', 'top', 'ongoing', 'problems', 'bel', '##ea', '##gue', '##red', 'russian', 'oil', 'giant', 'yu', '##kos', 'also', 'prompted', 'ie', '##a', 'rev', '##ise', 'output', 'estimates', 'russia', 'major', 'non', '##ope', '##c', 'supplier', 'think', 'prices', 'beginning', 'set', 'new', 'range', 'looks', 'like', 'level', 'said', 'energy', 'analyst', 'or', '##in', 'middleton', 'barclay', '##s', 'capital']\n"
     ]
    }
   ],
   "source": [
    "#Here is what the tokenised sample of the first training set observation looks like\n",
    "print(tokenizer.tokenize(train_InputExamples.iloc[0].text_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 1780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 1780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] crude oil prices surged back barrel mark thursday energy market watch ##dog raised forecast ##s global demand international energy agency ie ##a warned demand op ##ec ##s crude first quarter would outs ##trip supply ie ##a raised estimate oil demand growth barrels day million barrels day us light crude rose brent crude london gained paris ##base ##d ie ##a watch ##dog advises industrial ##ized nations energy policy said upward revision due stronger demand china asian countries fresh rally crude prices followed gains wednesday triggered large falls us crude supplies following cold spell north america january us department energy reported crude stock ##pile ##s fallen m barrels m top ongoing problems bel ##ea ##gue ##red russian oil giant yu ##kos also prompted ie ##a rev ##ise output estimates russia major non ##ope ##c supplier think prices beginning set new range looks like level said energy analyst or ##in middleton barclay ##s capital [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] crude oil prices surged back barrel mark thursday energy market watch ##dog raised forecast ##s global demand international energy agency ie ##a warned demand op ##ec ##s crude first quarter would outs ##trip supply ie ##a raised estimate oil demand growth barrels day million barrels day us light crude rose brent crude london gained paris ##base ##d ie ##a watch ##dog advises industrial ##ized nations energy policy said upward revision due stronger demand china asian countries fresh rally crude prices followed gains wednesday triggered large falls us crude supplies following cold spell north america january us department energy reported crude stock ##pile ##s fallen m barrels m top ongoing problems bel ##ea ##gue ##red russian oil giant yu ##kos also prompted ie ##a rev ##ise output estimates russia major non ##ope ##c supplier think prices beginning set new range looks like level said energy analyst or ##in middleton barclay ##s capital [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 13587 3514 7597 18852 2067 8460 2928 9432 2943 3006 3422 16168 2992 19939 2015 3795 5157 2248 2943 4034 29464 2050 7420 5157 6728 8586 2015 13587 2034 4284 2052 21100 24901 4425 29464 2050 2992 10197 3514 5157 3930 13826 2154 2454 13826 2154 2149 2422 13587 3123 12895 13587 2414 4227 3000 15058 2094 29464 2050 3422 16168 25453 3919 3550 3741 2943 3343 2056 10745 13921 2349 6428 5157 2859 4004 3032 4840 8320 13587 7597 2628 12154 9317 13330 2312 4212 2149 13587 6067 2206 3147 6297 2167 2637 2254 2149 2533 2943 2988 13587 4518 22090 2015 5357 1049 13826 1049 2327 7552 3471 19337 5243 9077 5596 2845 3514 5016 9805 15710 2036 9469 29464 2050 7065 5562 6434 10035 3607 2350 2512 17635 2278 17024 2228 7597 2927 2275 2047 2846 3504 2066 2504 2056 2943 12941 2030 2378 17756 23724 2015 3007 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 13587 3514 7597 18852 2067 8460 2928 9432 2943 3006 3422 16168 2992 19939 2015 3795 5157 2248 2943 4034 29464 2050 7420 5157 6728 8586 2015 13587 2034 4284 2052 21100 24901 4425 29464 2050 2992 10197 3514 5157 3930 13826 2154 2454 13826 2154 2149 2422 13587 3123 12895 13587 2414 4227 3000 15058 2094 29464 2050 3422 16168 25453 3919 3550 3741 2943 3343 2056 10745 13921 2349 6428 5157 2859 4004 3032 4840 8320 13587 7597 2628 12154 9317 13330 2312 4212 2149 13587 6067 2206 3147 6297 2167 2637 2254 2149 2533 2943 2988 13587 4518 22090 2015 5357 1049 13826 1049 2327 7552 3471 19337 5243 9077 5596 2845 3514 5016 9805 15710 2036 9469 29464 2050 7065 5562 6434 10035 3607 2350 2512 17635 2278 17024 2228 7597 2927 2275 2047 2846 3504 2066 2504 2056 2943 12941 2030 2378 17756 23724 2015 3007 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] us rock band re ##m forced cancel concerts bass player mike mills taken hospital suffering severe flu ##like symptoms band forced cut short monday nights show sheffield cancelled tuesday ##s glasgow date mills could hardly stand let alone play said re ##m spokesman added resting hospital remainder band played short acoustic set monday tuesday ##s gig res ##ched ##uled june ticket show glasgow advised retain ticket stu ##b attend new date bands spokesman said would review remaining dates day ##to ##day basis based doctors advice mills obviously want mike get better clearly want play shows rest assured soon possible said band still hopeful would able make wednesday date added spokesman re ##m played acc ##ous ##tic versions hits losing religion iv ##e high leaving new york one love sheffield arena audience monday band originally scheduled play four dates uk part world tour former drummer bill berry collapsed switzerland band tour suffered ru ##pt ##ured an ##eur ##ys ##m made full recovery leave band two years later [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] us rock band re ##m forced cancel concerts bass player mike mills taken hospital suffering severe flu ##like symptoms band forced cut short monday nights show sheffield cancelled tuesday ##s glasgow date mills could hardly stand let alone play said re ##m spokesman added resting hospital remainder band played short acoustic set monday tuesday ##s gig res ##ched ##uled june ticket show glasgow advised retain ticket stu ##b attend new date bands spokesman said would review remaining dates day ##to ##day basis based doctors advice mills obviously want mike get better clearly want play shows rest assured soon possible said band still hopeful would able make wednesday date added spokesman re ##m played acc ##ous ##tic versions hits losing religion iv ##e high leaving new york one love sheffield arena audience monday band originally scheduled play four dates uk part world tour former drummer bill berry collapsed switzerland band tour suffered ru ##pt ##ured an ##eur ##ys ##m made full recovery leave band two years later [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2149 2600 2316 2128 2213 3140 17542 6759 3321 2447 3505 6341 2579 2902 6114 5729 19857 10359 8030 2316 3140 3013 2460 6928 6385 2265 8533 8014 9857 2015 6785 3058 6341 2071 6684 3233 2292 2894 2377 2056 2128 2213 14056 2794 8345 2902 6893 2316 2209 2460 6490 2275 6928 9857 2015 15453 24501 7690 18696 2238 7281 2265 6785 9449 9279 7281 24646 2497 5463 2047 3058 4996 14056 2056 2052 3319 3588 5246 2154 3406 10259 3978 2241 7435 6040 6341 5525 2215 3505 2131 2488 4415 2215 2377 3065 2717 8916 2574 2825 2056 2316 2145 17772 2052 2583 2191 9317 3058 2794 14056 2128 2213 2209 16222 3560 4588 4617 4978 3974 4676 4921 2063 2152 2975 2047 2259 2028 2293 8533 5196 4378 6928 2316 2761 5115 2377 2176 5246 2866 2112 2088 2778 2280 7101 3021 10498 7798 5288 2316 2778 4265 21766 13876 12165 2019 11236 7274 2213 2081 2440 7233 2681 2316 2048 2086 2101 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2149 2600 2316 2128 2213 3140 17542 6759 3321 2447 3505 6341 2579 2902 6114 5729 19857 10359 8030 2316 3140 3013 2460 6928 6385 2265 8533 8014 9857 2015 6785 3058 6341 2071 6684 3233 2292 2894 2377 2056 2128 2213 14056 2794 8345 2902 6893 2316 2209 2460 6490 2275 6928 9857 2015 15453 24501 7690 18696 2238 7281 2265 6785 9449 9279 7281 24646 2497 5463 2047 3058 4996 14056 2056 2052 3319 3588 5246 2154 3406 10259 3978 2241 7435 6040 6341 5525 2215 3505 2131 2488 4415 2215 2377 3065 2717 8916 2574 2825 2056 2316 2145 17772 2052 2583 2191 9317 3058 2794 14056 2128 2213 2209 16222 3560 4588 4617 4978 3974 4676 4921 2063 2152 2975 2047 2259 2028 2293 8533 5196 4378 6928 2316 2761 5115 2377 2176 5246 2866 2112 2088 2778 2280 7101 3021 10498 7798 5288 2316 2778 4265 21766 13876 12165 2019 11236 7274 2213 2081 2440 7233 2681 2316 2048 2086 2101 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] chinese police detained three top executives milk firm yi ##li reports suggesting investigated em ##be ##zzle ##ment yi ##li full name inner mongolia yi ##li industrial confirmed chairman chief financial officer securities representative custody company china ##s third ##lar ##ges ##t milk producer hold emergency meeting debate issue yi ##li spokesman said may move ou ##st chairman zheng jun ##hua ##i spokesman say three detained police official xi ##nh ##ua news agency said arrest linked alleged em ##be ##zzle ##ment yi ##li recently subject intense media speculation financial operations executives suspected wrongly using m yuan m m company funds support management buy ##out back july yi ##lis shares suspended tuesday fallen monday company two main rivals market leader meng ##ni ##u dairy second place bright dairy dominate chinese milk market grown almost past five years analysts wondered scandal yi ##li latest be ##fall chinese companies year could followed revelations corporate wrong ##do ##ing investors wonder yi ##lis scandal one sl ##ew uncovered year isn ##t tip ice ##berg said chen hui ##qi ##n analyst hua ##tai securities [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] chinese police detained three top executives milk firm yi ##li reports suggesting investigated em ##be ##zzle ##ment yi ##li full name inner mongolia yi ##li industrial confirmed chairman chief financial officer securities representative custody company china ##s third ##lar ##ges ##t milk producer hold emergency meeting debate issue yi ##li spokesman said may move ou ##st chairman zheng jun ##hua ##i spokesman say three detained police official xi ##nh ##ua news agency said arrest linked alleged em ##be ##zzle ##ment yi ##li recently subject intense media speculation financial operations executives suspected wrongly using m yuan m m company funds support management buy ##out back july yi ##lis shares suspended tuesday fallen monday company two main rivals market leader meng ##ni ##u dairy second place bright dairy dominate chinese milk market grown almost past five years analysts wondered scandal yi ##li latest be ##fall chinese companies year could followed revelations corporate wrong ##do ##ing investors wonder yi ##lis scandal one sl ##ew uncovered year isn ##t tip ice ##berg said chen hui ##qi ##n analyst hua ##tai securities [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2822 2610 14620 2093 2327 12706 6501 3813 12316 3669 4311 9104 10847 7861 4783 17644 3672 12316 3669 2440 2171 5110 13906 12316 3669 3919 4484 3472 2708 3361 2961 12012 4387 9968 2194 2859 2015 2353 8017 8449 2102 6501 3135 2907 5057 3116 5981 3277 12316 3669 14056 2056 2089 2693 15068 3367 3472 20985 12022 14691 2072 14056 2360 2093 14620 2610 2880 8418 25311 6692 2739 4034 2056 6545 5799 6884 7861 4783 17644 3672 12316 3669 3728 3395 6387 2865 12143 3361 3136 12706 6878 29116 2478 1049 11237 1049 1049 2194 5029 2490 2968 4965 5833 2067 2251 12316 6856 6661 6731 9857 5357 6928 2194 2048 2364 9169 3006 3003 27955 3490 2226 11825 2117 2173 4408 11825 16083 2822 6501 3006 4961 2471 2627 2274 2086 18288 4999 9446 12316 3669 6745 2022 13976 2822 3316 2095 2071 2628 22191 5971 3308 3527 2075 9387 4687 12316 6856 9446 2028 22889 7974 14486 2095 3475 2102 5955 3256 4059 2056 8802 17504 14702 2078 12941 23064 15444 12012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2822 2610 14620 2093 2327 12706 6501 3813 12316 3669 4311 9104 10847 7861 4783 17644 3672 12316 3669 2440 2171 5110 13906 12316 3669 3919 4484 3472 2708 3361 2961 12012 4387 9968 2194 2859 2015 2353 8017 8449 2102 6501 3135 2907 5057 3116 5981 3277 12316 3669 14056 2056 2089 2693 15068 3367 3472 20985 12022 14691 2072 14056 2360 2093 14620 2610 2880 8418 25311 6692 2739 4034 2056 6545 5799 6884 7861 4783 17644 3672 12316 3669 3728 3395 6387 2865 12143 3361 3136 12706 6878 29116 2478 1049 11237 1049 1049 2194 5029 2490 2968 4965 5833 2067 2251 12316 6856 6661 6731 9857 5357 6928 2194 2048 2364 9169 3006 3003 27955 3490 2226 11825 2117 2173 4408 11825 16083 2822 6501 3006 4961 2471 2627 2274 2086 18288 4999 9446 12316 3669 6745 2022 13976 2822 3316 2095 2071 2628 22191 5971 3308 3527 2075 9387 4687 12316 6856 9446 2028 22889 7974 14486 2095 3475 2102 5955 3256 4059 2056 8802 17504 14702 2078 12941 23064 15444 12012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] writing microsoft word document dangerous business according document security firm works ##har ##e business documents contained sensitive information firms would want exposed survey firm revealed make matters worse companies questioned idea confidential information leaking report warns firms better job policing documents corporate compliance becomes binding sensitive information inadvertently leaked documents includes confidential contractual terms competitive information rivals would keen see special deals key customers said andrew pearson european boss works ##har ##e commissioned research e ##ffi ##cie ##ncies internet brought instant access information also created security control issues said problem particularly acute documents prepared using microsoft word way maintains hidden records editing changes documents get passed around worked amended different staff members sensitive information finds way documents poor control editing amend ##ing process mean information ex ##pu ##nged survives final edit ##s microsoft however provide add ##on tool windows pcs fix ##es problem remove hidden data add ##in tool use remove personal hidden data might immediately apparent view document microsoft office application says instructions microsoft ##s website microsoft recommends tool used people publish word document tool apple machines running word available works ##har ##e surveyed firms around world found average documents contained legally sensitive information many firms three [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] writing microsoft word document dangerous business according document security firm works ##har ##e business documents contained sensitive information firms would want exposed survey firm revealed make matters worse companies questioned idea confidential information leaking report warns firms better job policing documents corporate compliance becomes binding sensitive information inadvertently leaked documents includes confidential contractual terms competitive information rivals would keen see special deals key customers said andrew pearson european boss works ##har ##e commissioned research e ##ffi ##cie ##ncies internet brought instant access information also created security control issues said problem particularly acute documents prepared using microsoft word way maintains hidden records editing changes documents get passed around worked amended different staff members sensitive information finds way documents poor control editing amend ##ing process mean information ex ##pu ##nged survives final edit ##s microsoft however provide add ##on tool windows pcs fix ##es problem remove hidden data add ##in tool use remove personal hidden data might immediately apparent view document microsoft office application says instructions microsoft ##s website microsoft recommends tool used people publish word document tool apple machines running word available works ##har ##e surveyed firms around world found average documents contained legally sensitive information many firms three [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 3015 7513 2773 6254 4795 2449 2429 6254 3036 3813 2573 8167 2063 2449 5491 4838 7591 2592 9786 2052 2215 6086 5002 3813 3936 2191 5609 4788 3316 8781 2801 18777 2592 24325 3189 19428 9786 2488 3105 21107 5491 5971 12646 4150 8031 7591 2592 21089 15748 5491 2950 18777 27948 3408 6975 2592 9169 2052 10326 2156 2569 9144 3145 6304 2056 4080 12874 2647 5795 2573 8167 2063 4837 2470 1041 26989 23402 14767 4274 2716 7107 3229 2592 2036 2580 3036 2491 3314 2056 3291 3391 11325 5491 4810 2478 7513 2773 2126 9319 5023 2636 9260 3431 5491 2131 2979 2105 2499 13266 2367 3095 2372 7591 2592 4858 2126 5491 3532 2491 9260 27950 2075 2832 2812 2592 4654 14289 21558 13655 2345 10086 2015 7513 2174 3073 5587 2239 6994 3645 27019 8081 2229 3291 6366 5023 2951 5587 2378 6994 2224 6366 3167 5023 2951 2453 3202 6835 3193 6254 7513 2436 4646 2758 8128 7513 2015 4037 7513 26021 6994 2109 2111 10172 2773 6254 6994 6207 6681 2770 2773 2800 2573 8167 2063 12876 9786 2105 2088 2179 2779 5491 4838 10142 7591 2592 2116 9786 2093 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 3015 7513 2773 6254 4795 2449 2429 6254 3036 3813 2573 8167 2063 2449 5491 4838 7591 2592 9786 2052 2215 6086 5002 3813 3936 2191 5609 4788 3316 8781 2801 18777 2592 24325 3189 19428 9786 2488 3105 21107 5491 5971 12646 4150 8031 7591 2592 21089 15748 5491 2950 18777 27948 3408 6975 2592 9169 2052 10326 2156 2569 9144 3145 6304 2056 4080 12874 2647 5795 2573 8167 2063 4837 2470 1041 26989 23402 14767 4274 2716 7107 3229 2592 2036 2580 3036 2491 3314 2056 3291 3391 11325 5491 4810 2478 7513 2773 2126 9319 5023 2636 9260 3431 5491 2131 2979 2105 2499 13266 2367 3095 2372 7591 2592 4858 2126 5491 3532 2491 9260 27950 2075 2832 2812 2592 4654 14289 21558 13655 2345 10086 2015 7513 2174 3073 5587 2239 6994 3645 27019 8081 2229 3291 6366 5023 2951 5587 2378 6994 2224 6366 3167 5023 2951 2453 3202 6835 3193 6254 7513 2436 4646 2758 8128 7513 2015 4037 7513 26021 6994 2109 2111 10172 2773 6254 6994 6207 6681 2770 2773 2800 2573 8167 2063 12876 9786 2105 2088 2179 2779 5491 4838 10142 7591 2592 2116 9786 2093 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 4 (id = 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 4 (id = 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] snow patrol course action ask co ##fo ##under bassist leave band lead singer gary light ##body said mark mcc ##lellan ##d band years since formation dundee university light ##body said last months touring taken toll rest bands relationship said hardest decision ever make believe us say didn ##t make lightly group originally northern ireland achieved mainstream success last year single run award ##win ##ning album final straw statement bands website light ##body said started group mark years ago massive part snow patrol life throughout decade added got stage things couldn ##t go felt course action know distressed may understand news best band snow patrol currently working follow ##up breakthrough third album band set play support u number summer stadium gigs last month big winners ireland ##s top music honours meteor awards picking accolades best band album followed nominations brit awards mercury music prize band formed light ##body mcc ##lellan ##d met students dundee university [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] snow patrol course action ask co ##fo ##under bassist leave band lead singer gary light ##body said mark mcc ##lellan ##d band years since formation dundee university light ##body said last months touring taken toll rest bands relationship said hardest decision ever make believe us say didn ##t make lightly group originally northern ireland achieved mainstream success last year single run award ##win ##ning album final straw statement bands website light ##body said started group mark years ago massive part snow patrol life throughout decade added got stage things couldn ##t go felt course action know distressed may understand news best band snow patrol currently working follow ##up breakthrough third album band set play support u number summer stadium gigs last month big winners ireland ##s top music honours meteor awards picking accolades best band album followed nominations brit awards mercury music prize band formed light ##body mcc ##lellan ##d met students dundee university [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 4586 6477 2607 2895 3198 2522 14876 20824 9858 2681 2316 2599 3220 5639 2422 23684 2056 2928 23680 25839 2094 2316 2086 2144 4195 14252 2118 2422 23684 2056 2197 2706 6828 2579 9565 2717 4996 3276 2056 18263 3247 2412 2191 2903 2149 2360 2134 2102 2191 8217 2177 2761 2642 3163 4719 7731 3112 2197 2095 2309 2448 2400 10105 5582 2201 2345 13137 4861 4996 4037 2422 23684 2056 2318 2177 2928 2086 3283 5294 2112 4586 6477 2166 2802 5476 2794 2288 2754 2477 2481 2102 2175 2371 2607 2895 2113 24305 2089 3305 2739 2190 2316 4586 6477 2747 2551 3582 6279 12687 2353 2201 2316 2275 2377 2490 1057 2193 2621 3346 20929 2197 3204 2502 4791 3163 2015 2327 2189 8762 23879 2982 8130 27447 2190 2316 2201 2628 9930 28101 2982 8714 2189 3396 2316 2719 2422 23684 23680 25839 2094 2777 2493 14252 2118 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 4586 6477 2607 2895 3198 2522 14876 20824 9858 2681 2316 2599 3220 5639 2422 23684 2056 2928 23680 25839 2094 2316 2086 2144 4195 14252 2118 2422 23684 2056 2197 2706 6828 2579 9565 2717 4996 3276 2056 18263 3247 2412 2191 2903 2149 2360 2134 2102 2191 8217 2177 2761 2642 3163 4719 7731 3112 2197 2095 2309 2448 2400 10105 5582 2201 2345 13137 4861 4996 4037 2422 23684 2056 2318 2177 2928 2086 3283 5294 2112 4586 6477 2166 2802 5476 2794 2288 2754 2477 2481 2102 2175 2371 2607 2895 2113 24305 2089 3305 2739 2190 2316 4586 6477 2747 2551 3582 6279 12687 2353 2201 2316 2275 2377 2490 1057 2193 2621 3346 20929 2197 3204 2502 4791 3163 2015 2327 2189 8762 23879 2982 8130 27447 2190 2316 2201 2628 9930 28101 2982 8714 2189 3396 2316 2719 2422 23684 23680 25839 2094 2777 2493 14252 2118 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] actor ke ##anu reeves best known role matrix movies awarded star prestigious hollywood walk fame year ##old attended un ##ve ##iling star mother patricia thanked inspiring become actor years old asked mom ok actor reeves said said whatever want star th embedded pavement hollywood boulevard actor born lebanese capital beirut also spoke dropped school pursue acting career hollywood calling said got car british racing green volvo holes floor bricks holding seats young man full hopes dreams reeves first found fame teen comedy bill ted ##s excellent adventure went combine blockbuster ##s speed devils advocate matrix series smaller films including private idaho recently seen something ##s gotta give alongside jack nicholson diane ke ##aton next film supernatural thriller constantine released us later month opens uk march [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] actor ke ##anu reeves best known role matrix movies awarded star prestigious hollywood walk fame year ##old attended un ##ve ##iling star mother patricia thanked inspiring become actor years old asked mom ok actor reeves said said whatever want star th embedded pavement hollywood boulevard actor born lebanese capital beirut also spoke dropped school pursue acting career hollywood calling said got car british racing green volvo holes floor bricks holding seats young man full hopes dreams reeves first found fame teen comedy bill ted ##s excellent adventure went combine blockbuster ##s speed devils advocate matrix series smaller films including private idaho recently seen something ##s gotta give alongside jack nicholson diane ke ##aton next film supernatural thriller constantine released us later month opens uk march [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 3364 17710 24076 17891 2190 2124 2535 8185 5691 3018 2732 8919 5365 3328 4476 2095 11614 3230 4895 3726 16281 2732 2388 10717 15583 18988 2468 3364 2086 2214 2356 3566 7929 3364 17891 2056 2056 3649 2215 2732 16215 11157 14271 5365 8459 3364 2141 12592 3007 15335 2036 3764 3333 2082 7323 3772 2476 5365 4214 2056 2288 2482 2329 3868 2665 21074 8198 2723 14219 3173 4272 2402 2158 2440 8069 5544 17891 2034 2179 4476 9458 4038 3021 6945 2015 6581 6172 2253 11506 27858 2015 3177 13664 8175 8185 2186 3760 3152 2164 2797 9795 3728 2464 2242 2015 10657 2507 4077 2990 16955 12082 17710 22436 2279 2143 11189 10874 12790 2207 2149 2101 3204 7480 2866 2233 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 3364 17710 24076 17891 2190 2124 2535 8185 5691 3018 2732 8919 5365 3328 4476 2095 11614 3230 4895 3726 16281 2732 2388 10717 15583 18988 2468 3364 2086 2214 2356 3566 7929 3364 17891 2056 2056 3649 2215 2732 16215 11157 14271 5365 8459 3364 2141 12592 3007 15335 2036 3764 3333 2082 7323 3772 2476 5365 4214 2056 2288 2482 2329 3868 2665 21074 8198 2723 14219 3173 4272 2402 2158 2440 8069 5544 17891 2034 2179 4476 9458 4038 3021 6945 2015 6581 6172 2253 11506 27858 2015 3177 13664 8175 8185 2186 3760 3152 2164 2797 9795 3728 2464 2242 2015 10657 2507 4077 2990 16955 12082 17710 22436 2279 2143 11189 10874 12790 2207 2149 2101 3204 7480 2866 2233 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] labour party hold autumn conference manchester blackpool confirmed much trailed decision ratified labour ##s ruling national executive committee break traditional choice seaside venue first time since party chosen manchester host annual event blackpool get much smaller february spring conference instead seen pl ##aca ##tory move years main political parties rotated blackpool bournemouth brighton news much larger annual conference gather blackpool seen blow coastal resort party said would return blackpool following year bournemouth hosted event party signed two year deal brighton host autumn conference colin as ##plin blackpool hotel association said tried hard make sure come back blackpool obviously failed hope manchester handle crowds ama ##zes labour party working class party doesn ##t want come main working class resort country exact cost blackpool terms lost revenue hotel accommodation yet known thought block booking ##s taken major manchester hotels official announcement [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] labour party hold autumn conference manchester blackpool confirmed much trailed decision ratified labour ##s ruling national executive committee break traditional choice seaside venue first time since party chosen manchester host annual event blackpool get much smaller february spring conference instead seen pl ##aca ##tory move years main political parties rotated blackpool bournemouth brighton news much larger annual conference gather blackpool seen blow coastal resort party said would return blackpool following year bournemouth hosted event party signed two year deal brighton host autumn conference colin as ##plin blackpool hotel association said tried hard make sure come back blackpool obviously failed hope manchester handle crowds ama ##zes labour party working class party doesn ##t want come main working class resort country exact cost blackpool terms lost revenue hotel accommodation yet known thought block booking ##s taken major manchester hotels official announcement [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 4428 2283 2907 7114 3034 5087 17444 4484 2172 11145 3247 17673 4428 2015 6996 2120 3237 2837 3338 3151 3601 20276 6891 2034 2051 2144 2283 4217 5087 3677 3296 2724 17444 2131 2172 3760 2337 3500 3034 2612 2464 20228 19629 7062 2693 2086 2364 2576 4243 20931 17444 22882 10309 2739 2172 3469 3296 3034 8587 17444 2464 6271 5780 7001 2283 2056 2052 2709 17444 2206 2095 22882 4354 2724 2283 2772 2048 2095 3066 10309 3677 7114 3034 6972 2004 28296 17444 3309 2523 2056 2699 2524 2191 2469 2272 2067 17444 5525 3478 3246 5087 5047 12783 25933 11254 4428 2283 2551 2465 2283 2987 2102 2215 2272 2364 2551 2465 7001 2406 6635 3465 17444 3408 2439 6599 3309 11366 2664 2124 2245 3796 21725 2015 2579 2350 5087 9275 2880 8874 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 4428 2283 2907 7114 3034 5087 17444 4484 2172 11145 3247 17673 4428 2015 6996 2120 3237 2837 3338 3151 3601 20276 6891 2034 2051 2144 2283 4217 5087 3677 3296 2724 17444 2131 2172 3760 2337 3500 3034 2612 2464 20228 19629 7062 2693 2086 2364 2576 4243 20931 17444 22882 10309 2739 2172 3469 3296 3034 8587 17444 2464 6271 5780 7001 2283 2056 2052 2709 17444 2206 2095 22882 4354 2724 2283 2772 2048 2095 3066 10309 3677 7114 3034 6972 2004 28296 17444 3309 2523 2056 2699 2524 2191 2469 2272 2067 17444 5525 3478 3246 5087 5047 12783 25933 11254 4428 2283 2551 2465 2283 2987 2102 2215 2272 2364 2551 2465 7001 2406 6635 3465 17444 3408 2439 6599 3309 11366 2664 2124 2245 3796 21725 2015 2579 2350 5087 9275 2880 8874 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 2 (id = 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 2 (id = 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] us actor os ##sie davis found dead age davis married actress ruby dee found dead friday hotel room miami beach florida making film davis whose year career included credits producer director actor writer stage screen also civil rights activist miami beach police spokesman bobby hernandez said cause death appeared natural davis ##s body discovered grandson para ##med ##ics shore club hotel miami beach actor shooting film retirement mr hernandez said gaining entry found mr davis passed away cause death appears natural according grandson suffering heart disease davis ##s best known roles included joe louis story gone days film adapted play pu ##rl ##ie victorious also appeared spike lee movies including school daze right thing jungle fever film debut film way starring sydney po ##iti ##er ruby dee davis dee married years together received kennedy center honours body work actors equity association issued statement calling davis icon american theatre dee american treasures davis also prominent figure civil rights movement voice racial equality featured speaker funeral ##s martin luther king j ##nr malcolm x besides dee davis survived three children nora hasn ##a guy blues artist seven grandchildren [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] us actor os ##sie davis found dead age davis married actress ruby dee found dead friday hotel room miami beach florida making film davis whose year career included credits producer director actor writer stage screen also civil rights activist miami beach police spokesman bobby hernandez said cause death appeared natural davis ##s body discovered grandson para ##med ##ics shore club hotel miami beach actor shooting film retirement mr hernandez said gaining entry found mr davis passed away cause death appears natural according grandson suffering heart disease davis ##s best known roles included joe louis story gone days film adapted play pu ##rl ##ie victorious also appeared spike lee movies including school daze right thing jungle fever film debut film way starring sydney po ##iti ##er ruby dee davis dee married years together received kennedy center honours body work actors equity association issued statement calling davis icon american theatre dee american treasures davis also prominent figure civil rights movement voice racial equality featured speaker funeral ##s martin luther king j ##nr malcolm x besides dee davis survived three children nora hasn ##a guy blues artist seven grandchildren [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2149 3364 9808 11741 4482 2179 2757 2287 4482 2496 3883 10090 9266 2179 2757 5958 3309 2282 5631 3509 3516 2437 2143 4482 3005 2095 2476 2443 6495 3135 2472 3364 3213 2754 3898 2036 2942 2916 7423 5631 3509 2610 14056 6173 13688 2056 3426 2331 2596 3019 4482 2015 2303 3603 7631 11498 7583 6558 5370 2252 3309 5631 3509 3364 5008 2143 5075 2720 13688 2056 8550 4443 2179 2720 4482 2979 2185 3426 2331 3544 3019 2429 7631 6114 2540 4295 4482 2015 2190 2124 4395 2443 3533 3434 2466 2908 2420 2143 5967 2377 16405 12190 2666 13846 2036 2596 9997 3389 5691 2164 2082 28918 2157 2518 8894 9016 2143 2834 2143 2126 4626 3994 13433 25090 2121 10090 9266 4482 9266 2496 2086 2362 2363 5817 2415 8762 2303 2147 5889 10067 2523 3843 4861 4214 4482 12696 2137 3004 9266 2137 17605 4482 2036 4069 3275 2942 2916 2929 2376 5762 9945 2956 5882 6715 2015 3235 9678 2332 1046 16118 8861 1060 4661 9266 4482 5175 2093 2336 12306 8440 2050 3124 5132 3063 2698 13628 102 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2149 3364 9808 11741 4482 2179 2757 2287 4482 2496 3883 10090 9266 2179 2757 5958 3309 2282 5631 3509 3516 2437 2143 4482 3005 2095 2476 2443 6495 3135 2472 3364 3213 2754 3898 2036 2942 2916 7423 5631 3509 2610 14056 6173 13688 2056 3426 2331 2596 3019 4482 2015 2303 3603 7631 11498 7583 6558 5370 2252 3309 5631 3509 3364 5008 2143 5075 2720 13688 2056 8550 4443 2179 2720 4482 2979 2185 3426 2331 3544 3019 2429 7631 6114 2540 4295 4482 2015 2190 2124 4395 2443 3533 3434 2466 2908 2420 2143 5967 2377 16405 12190 2666 13846 2036 2596 9997 3389 5691 2164 2082 28918 2157 2518 8894 9016 2143 2834 2143 2126 4626 3994 13433 25090 2121 10090 9266 4482 9266 2496 2086 2362 2363 5817 2415 8762 2303 2147 5889 10067 2523 3843 4861 4214 4482 12696 2137 3004 9266 2137 17605 4482 2036 4069 3275 2942 2916 2929 2376 5762 9945 2956 5882 6715 2015 3235 9678 2332 1046 16118 8861 1060 4661 9266 4482 5175 2093 2336 12306 8440 2050 3124 5132 3063 2698 13628 102 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] computer firm apple issued lawsuit prevent online leaks information future products lawsuit unidentified individual comes weeks mac ##world conference san francisco used showcase new products complaint said unidentified individual recently mis ##app ##rop ##riated di ##sse ##minated confidential information lawsuit filed santa clara california superior court apple famously secretive future product launches apple users equally famous spec ##ulating new technology company fans speculated recent weeks possibility new type ipod announced mac ##world conference apple said seven ##page complaint filed december know true names capacities whether individual associate corporate otherwise defendants company said would amend complaint discovered names allegedly leaked information first time apple sued people posted information future products internet december apple sued former contractor allegedly posted online drawings images engineering details company ##s power ##mac g computer statement apple said current lawsuit apple filed civil complaint unnamed individuals believe stole trade secrets posted detailed information una ##nn ##oun ##ced apple product internet [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] computer firm apple issued lawsuit prevent online leaks information future products lawsuit unidentified individual comes weeks mac ##world conference san francisco used showcase new products complaint said unidentified individual recently mis ##app ##rop ##riated di ##sse ##minated confidential information lawsuit filed santa clara california superior court apple famously secretive future product launches apple users equally famous spec ##ulating new technology company fans speculated recent weeks possibility new type ipod announced mac ##world conference apple said seven ##page complaint filed december know true names capacities whether individual associate corporate otherwise defendants company said would amend complaint discovered names allegedly leaked information first time apple sued people posted information future products internet december apple sued former contractor allegedly posted online drawings images engineering details company ##s power ##mac g computer statement apple said current lawsuit apple filed civil complaint unnamed individuals believe stole trade secrets posted detailed information una ##nn ##oun ##ced apple product internet [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 3274 3813 6207 3843 9870 4652 3784 29324 2592 2925 3688 9870 20293 3265 3310 3134 6097 11108 3034 2624 3799 2109 13398 2047 3688 12087 2056 20293 3265 3728 28616 29098 18981 25475 4487 11393 26972 18777 2592 9870 6406 4203 10254 2662 6020 2457 6207 18172 28607 2925 4031 18989 6207 5198 8053 3297 28699 10924 2047 2974 2194 4599 15520 3522 3134 6061 2047 2828 26322 2623 6097 11108 3034 6207 2056 2698 13704 12087 6406 2285 2113 2995 3415 21157 3251 3265 5482 5971 4728 16362 2194 2056 2052 27950 12087 3603 3415 9382 15748 2592 2034 2051 6207 12923 2111 6866 2592 2925 3688 4274 2285 6207 12923 2280 13666 9382 6866 3784 9254 4871 3330 4751 2194 2015 2373 22911 1043 3274 4861 6207 2056 2783 9870 6207 6406 2942 12087 13294 3633 2903 10312 3119 7800 6866 6851 2592 14477 10695 23709 11788 6207 4031 4274 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 3274 3813 6207 3843 9870 4652 3784 29324 2592 2925 3688 9870 20293 3265 3310 3134 6097 11108 3034 2624 3799 2109 13398 2047 3688 12087 2056 20293 3265 3728 28616 29098 18981 25475 4487 11393 26972 18777 2592 9870 6406 4203 10254 2662 6020 2457 6207 18172 28607 2925 4031 18989 6207 5198 8053 3297 28699 10924 2047 2974 2194 4599 15520 3522 3134 6061 2047 2828 26322 2623 6097 11108 3034 6207 2056 2698 13704 12087 6406 2285 2113 2995 3415 21157 3251 3265 5482 5971 4728 16362 2194 2056 2052 27950 12087 3603 3415 9382 15748 2592 2034 2051 6207 12923 2111 6866 2592 2925 3688 4274 2285 6207 12923 2280 13666 9382 6866 3784 9254 4871 3330 4751 2194 2015 2373 22911 1043 3274 4861 6207 2056 2783 9870 6207 6406 2942 12087 13294 3633 2903 10312 3119 7800 6866 6851 2592 14477 10695 23709 11788 6207 4031 4274 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 4 (id = 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 4 (id = 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] labour ##s leadership put show unity campaign poster launch mps criticised tony blair gordon brown reports rift mr brown joined launch john prescott alan mil ##burn man controversial ##ly put charge election planning mr blair private meeting monday saw normally loyal mps warn feud ##ing could je ##opa ##rdi ##se election hopes follows new book charting disputes prime minister chancellor event first time mr mil ##burn shared platform chancellor since taking mr browns traditional poll planning role pair chat ##ted ami ##ca ##bly mr brown insisted happy current campaign task asked would deal claims trust prime minister mr brown replied see record economy british people trusting us run economy refused comment new book saying nobody distracted business government mr brown later told reporters course trust prime minister downing street cited comment reporters suggested mr brown pointedly failed deny claims told mr blair nothing could ever say could ever believe labour ##s new posters say britain enjoying lowest inflation since s lowest unemployment years lowest mortgage rates years urge voters let tori ##es take things backwards mr mil ##burn promised poll campaign upbeat confident else optimistic future country conservative co ##chai ##rman liam fox der ##ided photo call saying [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] labour ##s leadership put show unity campaign poster launch mps criticised tony blair gordon brown reports rift mr brown joined launch john prescott alan mil ##burn man controversial ##ly put charge election planning mr blair private meeting monday saw normally loyal mps warn feud ##ing could je ##opa ##rdi ##se election hopes follows new book charting disputes prime minister chancellor event first time mr mil ##burn shared platform chancellor since taking mr browns traditional poll planning role pair chat ##ted ami ##ca ##bly mr brown insisted happy current campaign task asked would deal claims trust prime minister mr brown replied see record economy british people trusting us run economy refused comment new book saying nobody distracted business government mr brown later told reporters course trust prime minister downing street cited comment reporters suggested mr brown pointedly failed deny claims told mr blair nothing could ever say could ever believe labour ##s new posters say britain enjoying lowest inflation since s lowest unemployment years lowest mortgage rates years urge voters let tori ##es take things backwards mr mil ##burn promised poll campaign upbeat confident else optimistic future country conservative co ##chai ##rman liam fox der ##ided photo call saying [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 4428 2015 4105 2404 2265 8499 3049 13082 4888 12616 10648 4116 10503 5146 2829 4311 16931 2720 2829 2587 4888 2198 20719 5070 23689 8022 2158 6801 2135 2404 3715 2602 4041 2720 10503 2797 3116 6928 2387 5373 8884 12616 11582 13552 2075 2071 15333 29477 17080 3366 2602 8069 4076 2047 2338 17918 11936 3539 2704 7306 2724 2034 2051 2720 23689 8022 4207 4132 7306 2144 2635 2720 13240 3151 8554 4041 2535 3940 11834 3064 26445 3540 6321 2720 2829 7278 3407 2783 3049 4708 2356 2052 3066 4447 3404 3539 2704 2720 2829 3880 2156 2501 4610 2329 2111 19836 2149 2448 4610 4188 7615 2047 2338 3038 6343 11116 2449 2231 2720 2829 2101 2409 12060 2607 3404 3539 2704 22501 2395 6563 7615 12060 4081 2720 2829 28713 3478 9772 4447 2409 2720 10503 2498 2071 2412 2360 2071 2412 2903 4428 2015 2047 14921 2360 3725 9107 7290 14200 2144 1055 7290 12163 2086 7290 14344 6165 2086 9075 7206 2292 23413 2229 2202 2477 11043 2720 23689 8022 5763 8554 3049 27999 9657 2842 21931 2925 2406 4603 2522 24925 14515 8230 4419 4315 14097 6302 2655 3038 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 4428 2015 4105 2404 2265 8499 3049 13082 4888 12616 10648 4116 10503 5146 2829 4311 16931 2720 2829 2587 4888 2198 20719 5070 23689 8022 2158 6801 2135 2404 3715 2602 4041 2720 10503 2797 3116 6928 2387 5373 8884 12616 11582 13552 2075 2071 15333 29477 17080 3366 2602 8069 4076 2047 2338 17918 11936 3539 2704 7306 2724 2034 2051 2720 23689 8022 4207 4132 7306 2144 2635 2720 13240 3151 8554 4041 2535 3940 11834 3064 26445 3540 6321 2720 2829 7278 3407 2783 3049 4708 2356 2052 3066 4447 3404 3539 2704 2720 2829 3880 2156 2501 4610 2329 2111 19836 2149 2448 4610 4188 7615 2047 2338 3038 6343 11116 2449 2231 2720 2829 2101 2409 12060 2607 3404 3539 2704 22501 2395 6563 7615 12060 4081 2720 2829 28713 3478 9772 4447 2409 2720 10503 2498 2071 2412 2360 2071 2412 2903 4428 2015 2047 14921 2360 3725 9107 7290 14200 2144 1055 7290 12163 2086 7290 14344 6165 2086 9075 7206 2292 23413 2229 2202 2477 11043 2720 23689 8022 5763 8554 3049 27999 9657 2842 21931 2925 2406 4603 2522 24925 14515 8230 4419 4315 14097 6302 2655 3038 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 2 (id = 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 2 (id = 2)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "2. Converting the train and validation features to InputFeatures that BERT understands.¶\n",
    "'''\n",
    "MAX_SEQ_LENGTH = 200\n",
    "\n",
    "train_features = run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "\n",
    "val_features = run_classifier.convert_examples_to_features(val_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence :  crude oil prices surged back  barrel mark thursday energy market watchdog raised forecasts global demand international energy agency iea warned demand opecs crude first quarter would outstrip supply iea raised estimate  oil demand growth   barrels day  million barrels day us light crude rose   brent crude london gained   parisbased iea watchdog advises industrialized nations energy policy said upward revision due stronger demand china asian countries fresh rally crude prices followed gains wednesday triggered large falls us crude supplies following cold spell north america january us department energy reported crude stockpiles fallen m barrels m top ongoing problems beleaguered russian oil giant yukos also prompted iea revise output estimates russia major nonopec supplier think prices beginning set new range looks like   level said energy analyst orin middleton barclays capital\n",
      "------------------------------\n",
      "Tokens :  ['crude', 'oil', 'prices', 'surged', 'back', 'barrel', 'mark', 'thursday', 'energy', 'market', 'watch', '##dog', 'raised', 'forecast', '##s', 'global', 'demand', 'international', 'energy', 'agency', 'ie', '##a', 'warned', 'demand', 'op', '##ec', '##s', 'crude', 'first', 'quarter', 'would', 'outs', '##trip', 'supply', 'ie', '##a', 'raised', 'estimate', 'oil', 'demand', 'growth', 'barrels', 'day', 'million', 'barrels', 'day', 'us', 'light', 'crude', 'rose', 'brent', 'crude', 'london', 'gained', 'paris', '##base', '##d', 'ie', '##a', 'watch', '##dog', 'advises', 'industrial', '##ized', 'nations', 'energy', 'policy', 'said', 'upward', 'revision', 'due', 'stronger', 'demand', 'china', 'asian', 'countries', 'fresh', 'rally', 'crude', 'prices', 'followed', 'gains', 'wednesday', 'triggered', 'large', 'falls', 'us', 'crude', 'supplies', 'following', 'cold', 'spell', 'north', 'america', 'january', 'us', 'department', 'energy', 'reported', 'crude', 'stock', '##pile', '##s', 'fallen', 'm', 'barrels', 'm', 'top', 'ongoing', 'problems', 'bel', '##ea', '##gue', '##red', 'russian', 'oil', 'giant', 'yu', '##kos', 'also', 'prompted', 'ie', '##a', 'rev', '##ise', 'output', 'estimates', 'russia', 'major', 'non', '##ope', '##c', 'supplier', 'think', 'prices', 'beginning', 'set', 'new', 'range', 'looks', 'like', 'level', 'said', 'energy', 'analyst', 'or', '##in', 'middleton', 'barclay', '##s', 'capital']\n",
      "------------------------------\n",
      "Input IDs :  [101, 13587, 3514, 7597, 18852, 2067, 8460, 2928, 9432, 2943, 3006, 3422, 16168, 2992, 19939, 2015, 3795, 5157, 2248, 2943, 4034, 29464, 2050, 7420, 5157, 6728, 8586, 2015, 13587, 2034, 4284, 2052, 21100, 24901, 4425, 29464, 2050, 2992, 10197, 3514, 5157, 3930, 13826, 2154, 2454, 13826, 2154, 2149, 2422, 13587, 3123, 12895, 13587, 2414, 4227, 3000, 15058, 2094, 29464, 2050, 3422, 16168, 25453, 3919, 3550, 3741, 2943, 3343, 2056, 10745, 13921, 2349, 6428, 5157, 2859, 4004, 3032, 4840, 8320, 13587, 7597, 2628, 12154, 9317, 13330, 2312, 4212, 2149, 13587, 6067, 2206, 3147, 6297, 2167, 2637, 2254, 2149, 2533, 2943, 2988, 13587, 4518, 22090, 2015, 5357, 1049, 13826, 1049, 2327, 7552, 3471, 19337, 5243, 9077, 5596, 2845, 3514, 5016, 9805, 15710, 2036, 9469, 29464, 2050, 7065, 5562, 6434, 10035, 3607, 2350, 2512, 17635, 2278, 17024, 2228, 7597, 2927, 2275, 2047, 2846, 3504, 2066, 2504, 2056, 2943, 12941, 2030, 2378, 17756, 23724, 2015, 3007, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "------------------------------\n",
      "Input Masks :  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "------------------------------\n",
      "Segment IDs :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "#Example on first observation in the training set\n",
    "print(\"Sentence : \", train_InputExamples.iloc[0].text_a)\n",
    "print(\"-\"*30)\n",
    "print(\"Tokens : \", tokenizer.tokenize(train_InputExamples.iloc[0].text_a))\n",
    "print(\"-\"*30)\n",
    "print(\"Input IDs : \", train_features[0].input_ids)\n",
    "print(\"-\"*30)\n",
    "print(\"Input Masks : \", train_features[0].input_mask)\n",
    "print(\"-\"*30)\n",
    "print(\"Segment IDs : \", train_features[0].segment_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating prediction model¶\n",
    "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n",
    "                 num_labels):\n",
    "  \n",
    "    bert_module = hub.Module(\n",
    "        BERT_MODEL_HUB,\n",
    "        trainable=True)\n",
    "    bert_inputs = dict(\n",
    "      input_ids=input_ids,\n",
    "      input_mask=input_mask,\n",
    "      segment_ids=segment_ids)\n",
    "    bert_outputs = bert_module(\n",
    "      inputs=bert_inputs,\n",
    "      signature=\"tokens\",\n",
    "      as_dict=True)\n",
    "\n",
    "    # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
    "    # Use \"sequence_outputs\" for token-level output.\n",
    "    output_layer = bert_outputs[\"pooled_output\"]\n",
    "    # with tf.Session() as sess:\n",
    "    output_layer1 = bert_outputs[\"pooled_output\"]\n",
    "    # output_layer1 = 999\n",
    "    hidden_size = output_layer.shape[-1].value\n",
    "\n",
    "    # Create our own layer to tune for politeness data.\n",
    "    output_weights = tf.get_variable(\n",
    "      \"output_weights\", [num_labels, hidden_size],\n",
    "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "    output_bias = tf.get_variable(\n",
    "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
    "\n",
    "    with tf.variable_scope(\"loss\"):\n",
    "\n",
    "        # Dropout helps prevent overfitting\n",
    "        output_layer = tf.nn.dropout(output_layer, keep_prob=0.8)\n",
    "\n",
    "        logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
    "        logits = tf.nn.bias_add(logits, output_bias)\n",
    "        log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "\n",
    "        # Convert labels into one-hot encoding\n",
    "        one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
    "\n",
    "        predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
    "        # If we're predicting, we want predicted labels and the probabiltiies.\n",
    "        if is_predicting:\n",
    "            return (predicted_labels, log_probs, output_layer1)\n",
    "\n",
    "        # If we're train/eval, compute loss between predicted and actual label\n",
    "        per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
    "        loss = tf.reduce_mean(per_example_loss)\n",
    "        \n",
    "        return (loss, predicted_labels, log_probs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn_builder(num_labels, learning_rate, num_train_steps,\n",
    "                     num_warmup_steps):\n",
    "    \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
    "    \n",
    "    def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
    "        \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
    "\n",
    "        input_ids = features[\"input_ids\"]\n",
    "        input_mask = features[\"input_mask\"]\n",
    "        segment_ids = features[\"segment_ids\"]\n",
    "        label_ids = features[\"label_ids\"]\n",
    "\n",
    "        is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
    "\n",
    "        # TRAIN and EVAL\n",
    "        if not is_predicting:\n",
    "\n",
    "            (loss, predicted_labels, log_probs) = create_model(\n",
    "            is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "\n",
    "            train_op = optimization.create_optimizer(\n",
    "              loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
    "\n",
    "            # Calculate evaluation metrics. \n",
    "            def metric_fn(label_ids, predicted_labels):\n",
    "                accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
    "                true_pos = tf.metrics.true_positives(\n",
    "                    label_ids,\n",
    "                    predicted_labels)\n",
    "                true_neg = tf.metrics.true_negatives(\n",
    "                    label_ids,\n",
    "                    predicted_labels)   \n",
    "                false_pos = tf.metrics.false_positives(\n",
    "                    label_ids,\n",
    "                    predicted_labels)  \n",
    "                false_neg = tf.metrics.false_negatives(\n",
    "                    label_ids,\n",
    "                    predicted_labels)\n",
    "\n",
    "                return {\n",
    "                    \"eval_accuracy\": accuracy,\n",
    "                    \"true_positives\": true_pos,\n",
    "                    \"true_negatives\": true_neg,\n",
    "                    \"false_positives\": false_pos,\n",
    "                    \"false_negatives\": false_neg,\n",
    "                    }\n",
    "\n",
    "            eval_metrics = metric_fn(label_ids, predicted_labels)\n",
    "\n",
    "            if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "                return tf.estimator.EstimatorSpec(mode=mode,\n",
    "                  loss=loss,\n",
    "                  train_op=train_op)\n",
    "            else:\n",
    "                return tf.estimator.EstimatorSpec(mode=mode,\n",
    "                    loss=loss,\n",
    "                    eval_metric_ops=eval_metrics)\n",
    "        else:\n",
    "            (predicted_labels, log_probs, output_layer) = create_model(\n",
    "            is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "            predictions = {\n",
    "              'probabilities': log_probs,\n",
    "              'labels': predicted_labels,\n",
    "              'pooled_output': output_layer\n",
    "            }\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "    # Return the actual model function in the closure\n",
    "    return model_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\py_37_t1x\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py:1750: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_TRAIN_EPOCHS = 1.0\n",
    "# Warmup is a period of time where the learning rate is small and gradually increases--usually helps training.\n",
    "WARMUP_PROPORTION = 0.1\n",
    "# Model configs\n",
    "SAVE_CHECKPOINTS_STEPS = 300\n",
    "SAVE_SUMMARY_STEPS = 100\n",
    "\n",
    "# Compute train and warmup steps from batch size\n",
    "num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
    "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
    "\n",
    "# Specify output directory and number of checkpoint steps to save\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    model_dir=OUTPUT_DIR,\n",
    "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
    "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)\n",
    "\n",
    "\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "session = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(445, 5)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_train_steps, len(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "##　Initializing the model and the estimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'bert_news_category', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 300, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000029F88F8A148>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'bert_news_category', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 300, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000029F88F8A148>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model_fn = model_fn_builder(\n",
    "  num_labels=len(label_list),\n",
    "  learning_rate=LEARNING_RATE,\n",
    "  num_train_steps=num_train_steps,\n",
    "  num_warmup_steps=num_warmup_steps)\n",
    "\n",
    "estimator = tf.estimator.Estimator(\n",
    "  model_fn=model_fn,\n",
    "  config=run_config,\n",
    "  params={\"batch_size\": BATCH_SIZE})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_fn = run_classifier.input_fn_builder(\n",
    "    features=train_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=True,\n",
    "    drop_remainder=False)\n",
    "\n",
    "# Create an input function for validating. drop_remainder = True for using TPUs.\n",
    "val_input_fn = run_classifier.input_fn_builder(\n",
    "    features=val_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=False,\n",
    "    drop_remainder=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Training!\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "d:\\anaconda3\\envs\\py_37_t1x\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into bert_news_category\\model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into bert_news_category\\model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.1573684, step = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.1573684, step = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.75962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.75962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.20016547, step = 100 (26.599 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.20016547, step = 100 (26.599 sec)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-104-29983b5267ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Beginning Training!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcurrent_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_train_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Training took time \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mcurrent_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\py_37_t1x\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 370\u001b[1;33m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    371\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss for final step: %s.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\py_37_t1x\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1159\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1160\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1161\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\py_37_t1x\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1193\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[0;32m   1194\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1195\u001b[1;33m                                              saving_listeners)\n\u001b[0m\u001b[0;32m   1196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1197\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\py_37_t1x\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[1;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[0;32m   1492\u001b[0m       \u001b[0many_step_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1493\u001b[0m       \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1494\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1495\u001b[0m         \u001b[0many_step_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1496\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0many_step_done\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\py_37_t1x\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m         run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m    755\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\py_37_t1x\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1257\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1258\u001b[0m             \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1259\u001b[1;33m             run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m   1260\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1261\u001b[0m         logging.info(\n",
      "\u001b[1;32md:\\anaconda3\\envs\\py_37_t1x\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1343\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1344\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1345\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1346\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\py_37_t1x\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1416\u001b[0m         \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m         \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m         run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\py_37_t1x\\lib\\site-packages\\tensorflow_core\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1176\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1178\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\py_37_t1x\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 956\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    957\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\py_37_t1x\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1180\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1181\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\py_37_t1x\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1359\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\py_37_t1x\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1363\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\py_37_t1x\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m-> 1350\u001b[1;33m                                       target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\py_37_t1x\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m                                             run_metadata)\n\u001b[0m\u001b[0;32m   1444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1445\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "# Training\n",
    "#\n",
    "print(f'Beginning Training!')\n",
    "current_time = datetime.now()\n",
    "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
    "print(\"Training took time \", datetime.now() - current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation\n",
    "#Evaluating the model with Validation set\n",
    "estimator.evaluate(input_fn=val_input_fn, steps=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
